% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hmatch_tokens.R
\name{hmatch_tokens}
\alias{hmatch_tokens}
\title{Hierarchical matching with tokenization of multi-term values}
\usage{
hmatch_tokens(
  raw,
  ref,
  pattern,
  pattern_ref = pattern,
  by,
  by_ref = by,
  type = "left",
  allow_gaps = TRUE,
  always_tokenize = FALSE,
  token_split = "_",
  exclude_freq = 3,
  exclude_nchar = 3,
  exclude_values = NULL,
  fuzzy = FALSE,
  fuzzy_method = "osa",
  fuzzy_dist = 1L,
  dict = NULL,
  ref_prefix = "ref_",
  std_fn = string_std,
  ...
)
}
\arguments{
\item{raw}{data frame containing hierarchical columns with raw data}

\item{ref}{data frame containing hierarchical columns with reference data}

\item{pattern}{regex pattern to match the hierarchical columns in \code{raw}\cr

\strong{Note:} hierarchical column names can be matched using either the \code{pattern}
\emph{or} \code{by} arguments. Or, if neither \code{pattern} or \code{by} are specified, the
hierarchical columns are assumed to be all column names that are common to
both \code{raw} and \code{ref}. See \link{specifying_columns}.}

\item{pattern_ref}{regex pattern to match the hierarchical columns in \code{ref}.
Defaults to \code{pattern}, so only need to specify if the hierarchical columns
have different names in \code{raw} and \code{ref}.}

\item{by}{vector giving the names of the hierarchical columns in \code{raw}}

\item{by_ref}{vector giving the names of the hierarchical columns in \code{ref}.
Defaults to \code{by}, so only need to specify if the hierarchical columns
have different names in \code{raw} and \code{ref}.}

\item{type}{type of join ("left", "inner", "anti", "resolve_left",
"resolve_inner", or "resolve_anti"). Defaults to "left". See
\link{join_types}.}

\item{allow_gaps}{logical indicating whether to allow missing values below
the match level, where 'match level' is the highest level with a
non-missing value within a given row of \code{raw}. Defaults to \code{TRUE}.}

\item{always_tokenize}{logical indicating whether to tokenize all values
prior to matching (\code{TRUE}), or to first attempt non-tokenized matching with
\code{\link{hmatch}} and only tokenize values within \code{raw} (and
corresponding putative matches within \code{ref}) that don't have a
non-tokenized match (\code{FALSE}). Defaults to \code{FALSE}.}

\item{token_split}{regex pattern to split strings into tokens. Currently
tokenization is implemented \emph{after}
\link[=string_standardization]{string-standardizatipn} with argument
\code{std_fn} (this may change in a future version), so the regex pattern should
split \emph{standardized} strings rather than the original strings. Defaults to
"_".}

\item{exclude_freq}{exclude tokens from matching if they have a frequency
greater than or equal to this value. Refers to the number of unique,
string-standardized values at a given hierarchical level in which a given
token occurs, as calculated by \code{\link{count_tokens}} (separately for
\code{raw} and \code{ref}). Defaults to \code{3}.}

\item{exclude_nchar}{exclude tokens from matching if they have \link{nchar}
less than or equal to this value. Defaults to \code{3}.}

\item{exclude_values}{character vector of additional tokens to exclude from
matching. Subject to \link[=string_standardization]{string-standardizatipn}
with argument \code{std_fn}.}

\item{fuzzy}{logical indicating whether to use fuzzy-matching (based on the
\code{\link{stringdist}} package). Defaults to FALSE.}

\item{fuzzy_method}{if \code{fuzzy = TRUE}, the method to use for string distance
calculation (see \link[stringdist]{stringdist-metrics}). Defaults to "osa".}

\item{fuzzy_dist}{if \code{fuzzy = TRUE}, the maximum string distance to use to
classify matches (i.e. a string distance â‰¤ \code{fuzzy_dist} will be considered
matching). Defaults to \code{1L}.}

\item{dict}{optional dictionary for recoding values within the hierarchical
columns of \code{raw} (see \link{dictionary_recoding})}

\item{ref_prefix}{prefix to add to names of returned columns from \code{ref} if
they are otherwise identical to names within \code{raw}. Defaults to "ref_".}

\item{std_fn}{function to standardize strings during matching. Defaults to
\code{\link{string_std}}. Set to \code{NULL} to omit standardization. See
also \link{string_standardization}.}

\item{...}{additional arguments passed to \code{std_fn()}}
}
\value{
a data frame obtained by matching the hierarchical columns in \code{raw}
and \code{ref}, using the join type specified by argument \code{type} (see
\link{join_types} for more details)
}
\description{
Match sets of hierarchical values (e.g. province / county / township) in a
raw, messy dataset to corresponding values within a reference dataset, using
tokenization to help match multi-term values that might otherwise be
difficult to match (e.g. "New York City" vs. "New York").

Includes options for ignoring matches from frequently-occurring tokens (e.g.
"North", "South", "City"), small tokens (e.g. "El", "San", "New"), or any
other set of tokens specified by the user.
}
\section{Resolve joins}{

Uses the same approach to resolve joins as \code{\link{hmatch}}.
}

\examples{
data(ne_raw)
data(ne_ref)

# add tokens to some values within ref to illustrate tokenized matching
ne_ref$adm0[ne_ref$adm0 == "United States"] <- "United States of America"
ne_ref$adm1[ne_ref$adm1 == "New York"] <- "New York State"

hmatch_tokens(ne_raw, ne_ref, type = "inner")

}
